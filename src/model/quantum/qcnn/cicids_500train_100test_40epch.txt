/mnt/slurm_nfs/j32abrah/ece-733-quantum-ml/src/model/quantum/qcnn/cicids_qcnn_quantum.py:48: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77) have mixed types. Specify dtype option on import or set low_memory=False.
  return pd.read_csv(path, header=None, names=columns, sep=",", skipinitialspace=True)
/mnt/slurm_nfs/j32abrah/ece-733-quantum-ml/src/model/quantum/qcnn/cicids_qcnn_quantum.py:104: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  X_test.replace([np.inf, -np.inf], np.nan, inplace=True)
/mnt/slurm_nfs/j32abrah/ece-733-quantum-ml/src/model/quantum/qcnn/cicids_qcnn_quantum.py:240: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.
  qnn = EstimatorQNN(

=== Data Distribution ===
                   class_label  samples     pct
0                       BENIGN  2273097  80.300
1                     DoS Hulk   231073   8.163
2                     PortScan   158930   5.614
3                         DDoS   128027   4.523
4                DoS GoldenEye    10293   0.364
5                  FTP-Patator     7938   0.280
6                  SSH-Patator     5897   0.208
7                DoS slowloris     5796   0.205
8             DoS Slowhttptest     5499   0.194
9                          Bot     1966   0.069
10    Web Attack � Brute Force     1507   0.053
11            Web Attack � XSS      652   0.023
12                Infiltration       36   0.001
13  Web Attack � Sql Injection       21   0.001
14                  Heartbleed       11   0.000
15                       Label        1   0.000

=== Train Distribution ===
                class_label  samples   pct
0                    BENIGN      405  81.0
1                  DoS Hulk       38   7.6
2                  PortScan       27   5.4
3                      DDoS       20   4.0
4               FTP-Patator        4   0.8
5             DoS GoldenEye        3   0.6
6          DoS Slowhttptest        1   0.2
7  Web Attack � Brute Force        1   0.2
8             DoS slowloris        1   0.2

=== Test Distribution ===
     class_label  samples   pct
0         BENIGN       83  83.0
1           DDoS       10  10.0
2       DoS Hulk        3   3.0
3       PortScan        2   2.0
4  DoS slowloris        1   1.0
5    SSH-Patator        1   1.0
Train label counts:
 label_binary
0    405
1     95
Name: count, dtype: int64
Test label counts:
 label_binary
0    83
1    17
Name: count, dtype: int64
Class weights: {np.int64(0): np.float64(0.6172839506172839), np.int64(1): np.float64(2.6315789473684212)}
PCA shapes: X_train: (500, 4) X_test: (100, 4)
Torch tensor shapes: X_train: torch.Size([500, 4]) X_test: torch.Size([100, 4])
Epoch 1/40 — Loss: 1.014230
Epoch 2/40 — Loss: 0.984268
Epoch 3/40 — Loss: 0.956149
Epoch 4/40 — Loss: 0.929259
Epoch 5/40 — Loss: 0.903010
Epoch 6/40 — Loss: 0.879312
Epoch 7/40 — Loss: 0.857304
Epoch 8/40 — Loss: 0.835818
Epoch 9/40 — Loss: 0.816722
Epoch 10/40 — Loss: 0.798372
Epoch 11/40 — Loss: 0.781084
Epoch 12/40 — Loss: 0.765309
Epoch 13/40 — Loss: 0.750562
Epoch 14/40 — Loss: 0.736630
Epoch 15/40 — Loss: 0.723804
Epoch 16/40 — Loss: 0.711827
Epoch 17/40 — Loss: 0.700710
Epoch 18/40 — Loss: 0.690294
Epoch 19/40 — Loss: 0.680460
Epoch 20/40 — Loss: 0.671284
Epoch 21/40 — Loss: 0.662526
Epoch 22/40 — Loss: 0.654147
Epoch 23/40 — Loss: 0.646313
Epoch 24/40 — Loss: 0.639131
Epoch 25/40 — Loss: 0.632300
Epoch 26/40 — Loss: 0.625474
Epoch 27/40 — Loss: 0.619259
Epoch 28/40 — Loss: 0.613068
Epoch 29/40 — Loss: 0.607480
Epoch 30/40 — Loss: 0.602179
Epoch 31/40 — Loss: 0.596860
Epoch 32/40 — Loss: 0.591865
Epoch 33/40 — Loss: 0.587197
Epoch 34/40 — Loss: 0.582566
Epoch 35/40 — Loss: 0.578119
Epoch 36/40 — Loss: 0.573937
Epoch 37/40 — Loss: 0.569774
Epoch 38/40 — Loss: 0.565891
Epoch 39/40 — Loss: 0.562079
Epoch 40/40 — Loss: 0.558370
Training time: 4832.09 seconds
Logits: tensor([-0.9713, -0.9417, -0.9653, -0.8984,  0.6437,  0.6434, -0.2915, -0.0131,
        -0.9509, -0.9745, -0.9343, -0.1842, -0.9788, -0.8887, -0.1117, -0.9787,
        -0.9763, -0.9750,  0.3384, -0.9545, -0.9412, -0.8809,  0.5286,  0.0565,
        -0.9801, -0.8868, -0.9707,  0.4782, -0.9489, -0.9716, -0.9734,  0.0934,
        -0.9791,  0.1691,  0.5934,  0.1593,  0.3063, -0.8970, -0.1232, -0.9034,
        -0.8810, -0.9013, -0.9414,  0.6756, -0.8165, -0.9800, -0.9573,  0.0439,
        -0.9610,  0.5506, -0.9763, -0.9579, -0.9113, -0.5755, -0.9740,  1.0247,
        -0.9815, -0.9326, -0.9436, -0.9759, -0.9774, -0.8766, -0.8971, -0.9225,
        -0.9756, -0.8952,  0.6269, -0.4289, -0.9770, -0.9522, -0.8869, -0.9782,
         1.0440, -0.9751, -0.9812, -0.7701, -0.9415, -0.9517, -0.5509, -0.9537,
         0.4827, -0.1729, -0.9325, -0.9563, -0.9726, -0.3587, -0.7774, -0.9707,
        -0.0332, -0.9575, -0.9545, -0.9027, -0.9582, -0.8958, -0.9768,  0.3646,
        -0.9739,  0.3399, -0.9783, -0.9544])
Probabilities: tensor([0.2746, 0.2806, 0.2758, 0.2894, 0.6556, 0.6555, 0.4276, 0.4967, 0.2787,
        0.2740, 0.2820, 0.4541, 0.2731, 0.2914, 0.4721, 0.2731, 0.2736, 0.2739,
        0.5838, 0.2780, 0.2807, 0.2930, 0.6291, 0.5141, 0.2729, 0.2918, 0.2747,
        0.6173, 0.2791, 0.2746, 0.2742, 0.5233, 0.2731, 0.5422, 0.6441, 0.5398,
        0.5760, 0.2897, 0.4692, 0.2883, 0.2930, 0.2888, 0.2806, 0.6628, 0.3065,
        0.2729, 0.2774, 0.5110, 0.2767, 0.6343, 0.2736, 0.2773, 0.2867, 0.3600,
        0.2741, 0.7359, 0.2726, 0.2824, 0.2802, 0.2737, 0.2734, 0.2939, 0.2896,
        0.2845, 0.2738, 0.2900, 0.6518, 0.3944, 0.2735, 0.2784, 0.2918, 0.2733,
        0.7396, 0.2739, 0.2727, 0.3165, 0.2806, 0.2785, 0.3656, 0.2781, 0.6184,
        0.4569, 0.2824, 0.2776, 0.2744, 0.4113, 0.3149, 0.2747, 0.4917, 0.2774,
        0.2780, 0.2885, 0.2772, 0.2899, 0.2735, 0.5902, 0.2741, 0.5842, 0.2732,
        0.2780])
Predictions: tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 1., 0., 0.])
Test Accuracy: 81.00%
Evaluation time: 0.15 seconds
Saved QCNN classifier state to qcnn_nsl_kdd_torch.pth
